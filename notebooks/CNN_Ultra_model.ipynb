{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.257611Z",
     "start_time": "2026-02-03T16:26:28.248868Z"
    }
   },
   "source": [
    "# MNIST dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# loader\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "\n",
    "# neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# for deep copy\n",
    "import copy"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.281209Z",
     "start_time": "2026-02-03T16:26:28.272373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataset class\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.x, self.y = torch.load(filepath)\n",
    "        self.x = self.x.view(-1, 1, 28, 28)\n",
    "        self.x = self.x / 255.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "id": "e3af72e1d2fe41a3",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.452063Z",
     "start_time": "2026-02-03T16:26:28.293536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load and concat datasets\n",
    "mnist_train = CTDataset('../data/MNIST/processed/training.pt')\n",
    "mnist_test = CTDataset('../data/MNIST/processed/test.pt')\n",
    "digits_train = CTDataset('../data/personal/digits_training.pt')\n",
    "digits_test = CTDataset('../data/personal/digits_test.pt')\n",
    "\n",
    "train_ds = ConcatDataset([mnist_train, digits_train])\n",
    "test_ds = ConcatDataset([mnist_test, digits_test])"
   ],
   "id": "33e9ba3a31be0119",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.474539Z",
     "start_time": "2026-02-03T16:26:28.465457Z"
    }
   },
   "cell_type": "code",
   "source": "type(train_ds)",
   "id": "25611945a1e364fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.ConcatDataset"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.523315Z",
     "start_time": "2026-02-03T16:26:28.516322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# see if numbers are ok\n",
    "def visualize_data(data):\n",
    "    img = data[0].numpy()\n",
    "    label = data[1].argmax()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()"
   ],
   "id": "347cd4025b865574",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.550142Z",
     "start_time": "2026-02-03T16:26:28.543873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=100, shuffle=True),\n",
    "    'test': DataLoader(test_ds, batch_size=100, shuffle=False)\n",
    "}"
   ],
   "id": "ab9b2ae07fb5813",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.561064Z",
     "start_time": "2026-02-03T16:26:28.555916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "class CNN_Ultra(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN_Ultra, self).__init__()\n",
    "\n",
    "        # Layer 1: Learn basic shapes (curves, lines)\n",
    "        # Input: (1, 28, 28) -> Output: (32, 28, 28)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Pool reduces to (32, 14, 14)\n",
    "\n",
    "        # Layer 2: Learn combinations of shapes (loops, corners)\n",
    "        # Input: (32, 14, 14) -> Output: (64, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # Pool reduces to (64, 7, 7)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        # We flattened 64 channels * 7 * 7 pixels = 3136\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.dropout = nn.Dropout(0.5) # Crucial to prevent overfitting on the 8 fonts\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1) # Flatten (Batch_Size, 3136)\n",
    "\n",
    "        # Classifier\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "6b0098c2ada111f4",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:26:28.578734Z",
     "start_time": "2026-02-03T16:26:28.566330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate and define training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN_Ultra().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()   # put model in training mode\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()   # initialize with 0\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loaders['train'].dataset),\n",
    "                100. * batch_idx / len(loaders['train']), loss.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
    "    return test_loss"
   ],
   "id": "41afc70ece7c0c05",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:33:40.576486Z",
     "start_time": "2026-02-03T16:26:28.587586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "def train_until_best(epochs, patience=5):\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(epoch)\n",
    "        test_loss = test()\n",
    "\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            patience_counter = 0\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "    if best_model_wts is not None:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        torch.save(model.state_dict(), '../models/CNN_Ultra.pth')\n",
    "        print('Best model saved!')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_until_best(100, patience=5)"
   ],
   "id": "294f6fdbf8093f07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/132000 (0%)]\tLoss: 2.408971\n",
      "Train Epoch: 1 [10000/132000 (8%)]\tLoss: 0.142575\n",
      "Train Epoch: 1 [20000/132000 (15%)]\tLoss: 0.109464\n",
      "Train Epoch: 1 [30000/132000 (23%)]\tLoss: 0.066225\n",
      "Train Epoch: 1 [40000/132000 (30%)]\tLoss: 0.095007\n",
      "Train Epoch: 1 [50000/132000 (38%)]\tLoss: 0.061703\n",
      "Train Epoch: 1 [60000/132000 (45%)]\tLoss: 0.139804\n",
      "Train Epoch: 1 [70000/132000 (53%)]\tLoss: 0.082304\n",
      "Train Epoch: 1 [80000/132000 (61%)]\tLoss: 0.078789\n",
      "Train Epoch: 1 [90000/132000 (68%)]\tLoss: 0.093572\n",
      "Train Epoch: 1 [100000/132000 (76%)]\tLoss: 0.098052\n",
      "Train Epoch: 1 [110000/132000 (83%)]\tLoss: 0.037972\n",
      "Train Epoch: 1 [120000/132000 (91%)]\tLoss: 0.063318\n",
      "Train Epoch: 1 [130000/132000 (98%)]\tLoss: 0.017643\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 17819/18000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/132000 (0%)]\tLoss: 0.033132\n",
      "Train Epoch: 2 [10000/132000 (8%)]\tLoss: 0.029177\n",
      "Train Epoch: 2 [20000/132000 (15%)]\tLoss: 0.042768\n",
      "Train Epoch: 2 [30000/132000 (23%)]\tLoss: 0.022056\n",
      "Train Epoch: 2 [40000/132000 (30%)]\tLoss: 0.043194\n",
      "Train Epoch: 2 [50000/132000 (38%)]\tLoss: 0.245806\n",
      "Train Epoch: 2 [60000/132000 (45%)]\tLoss: 0.032541\n",
      "Train Epoch: 2 [70000/132000 (53%)]\tLoss: 0.025662\n",
      "Train Epoch: 2 [80000/132000 (61%)]\tLoss: 0.020571\n",
      "Train Epoch: 2 [90000/132000 (68%)]\tLoss: 0.165030\n",
      "Train Epoch: 2 [100000/132000 (76%)]\tLoss: 0.033920\n",
      "Train Epoch: 2 [110000/132000 (83%)]\tLoss: 0.082746\n",
      "Train Epoch: 2 [120000/132000 (91%)]\tLoss: 0.010405\n",
      "Train Epoch: 2 [130000/132000 (98%)]\tLoss: 0.035033\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 17866/18000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/132000 (0%)]\tLoss: 0.118535\n",
      "Train Epoch: 3 [10000/132000 (8%)]\tLoss: 0.009605\n",
      "Train Epoch: 3 [20000/132000 (15%)]\tLoss: 0.111645\n",
      "Train Epoch: 3 [30000/132000 (23%)]\tLoss: 0.055078\n",
      "Train Epoch: 3 [40000/132000 (30%)]\tLoss: 0.061962\n",
      "Train Epoch: 3 [50000/132000 (38%)]\tLoss: 0.137596\n",
      "Train Epoch: 3 [60000/132000 (45%)]\tLoss: 0.057650\n",
      "Train Epoch: 3 [70000/132000 (53%)]\tLoss: 0.051046\n",
      "Train Epoch: 3 [80000/132000 (61%)]\tLoss: 0.033701\n",
      "Train Epoch: 3 [90000/132000 (68%)]\tLoss: 0.071321\n",
      "Train Epoch: 3 [100000/132000 (76%)]\tLoss: 0.069970\n",
      "Train Epoch: 3 [110000/132000 (83%)]\tLoss: 0.016764\n",
      "Train Epoch: 3 [120000/132000 (91%)]\tLoss: 0.056556\n",
      "Train Epoch: 3 [130000/132000 (98%)]\tLoss: 0.023824\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17898/18000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/132000 (0%)]\tLoss: 0.028872\n",
      "Train Epoch: 4 [10000/132000 (8%)]\tLoss: 0.018171\n",
      "Train Epoch: 4 [20000/132000 (15%)]\tLoss: 0.031182\n",
      "Train Epoch: 4 [30000/132000 (23%)]\tLoss: 0.031813\n",
      "Train Epoch: 4 [40000/132000 (30%)]\tLoss: 0.034396\n",
      "Train Epoch: 4 [50000/132000 (38%)]\tLoss: 0.054925\n",
      "Train Epoch: 4 [60000/132000 (45%)]\tLoss: 0.007136\n",
      "Train Epoch: 4 [70000/132000 (53%)]\tLoss: 0.003419\n",
      "Train Epoch: 4 [80000/132000 (61%)]\tLoss: 0.048047\n",
      "Train Epoch: 4 [90000/132000 (68%)]\tLoss: 0.012325\n",
      "Train Epoch: 4 [100000/132000 (76%)]\tLoss: 0.026446\n",
      "Train Epoch: 4 [110000/132000 (83%)]\tLoss: 0.011759\n",
      "Train Epoch: 4 [120000/132000 (91%)]\tLoss: 0.020740\n",
      "Train Epoch: 4 [130000/132000 (98%)]\tLoss: 0.003843\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17914/18000 (100%)\n",
      "\n",
      "Train Epoch: 5 [0/132000 (0%)]\tLoss: 0.014253\n",
      "Train Epoch: 5 [10000/132000 (8%)]\tLoss: 0.003732\n",
      "Train Epoch: 5 [20000/132000 (15%)]\tLoss: 0.121909\n",
      "Train Epoch: 5 [30000/132000 (23%)]\tLoss: 0.020477\n",
      "Train Epoch: 5 [40000/132000 (30%)]\tLoss: 0.012450\n",
      "Train Epoch: 5 [50000/132000 (38%)]\tLoss: 0.027051\n",
      "Train Epoch: 5 [60000/132000 (45%)]\tLoss: 0.004984\n",
      "Train Epoch: 5 [70000/132000 (53%)]\tLoss: 0.030304\n",
      "Train Epoch: 5 [80000/132000 (61%)]\tLoss: 0.004534\n",
      "Train Epoch: 5 [90000/132000 (68%)]\tLoss: 0.002705\n",
      "Train Epoch: 5 [100000/132000 (76%)]\tLoss: 0.002843\n",
      "Train Epoch: 5 [110000/132000 (83%)]\tLoss: 0.013337\n",
      "Train Epoch: 5 [120000/132000 (91%)]\tLoss: 0.004966\n",
      "Train Epoch: 5 [130000/132000 (98%)]\tLoss: 0.056597\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17925/18000 (100%)\n",
      "\n",
      "Train Epoch: 6 [0/132000 (0%)]\tLoss: 0.020181\n",
      "Train Epoch: 6 [10000/132000 (8%)]\tLoss: 0.023072\n",
      "Train Epoch: 6 [20000/132000 (15%)]\tLoss: 0.002840\n",
      "Train Epoch: 6 [30000/132000 (23%)]\tLoss: 0.014309\n",
      "Train Epoch: 6 [40000/132000 (30%)]\tLoss: 0.021195\n",
      "Train Epoch: 6 [50000/132000 (38%)]\tLoss: 0.034148\n",
      "Train Epoch: 6 [60000/132000 (45%)]\tLoss: 0.011170\n",
      "Train Epoch: 6 [70000/132000 (53%)]\tLoss: 0.042399\n",
      "Train Epoch: 6 [80000/132000 (61%)]\tLoss: 0.042603\n",
      "Train Epoch: 6 [90000/132000 (68%)]\tLoss: 0.008623\n",
      "Train Epoch: 6 [100000/132000 (76%)]\tLoss: 0.060997\n",
      "Train Epoch: 6 [110000/132000 (83%)]\tLoss: 0.014369\n",
      "Train Epoch: 6 [120000/132000 (91%)]\tLoss: 0.007830\n",
      "Train Epoch: 6 [130000/132000 (98%)]\tLoss: 0.015906\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17900/18000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/132000 (0%)]\tLoss: 0.002567\n",
      "Train Epoch: 7 [10000/132000 (8%)]\tLoss: 0.008210\n",
      "Train Epoch: 7 [20000/132000 (15%)]\tLoss: 0.094280\n",
      "Train Epoch: 7 [30000/132000 (23%)]\tLoss: 0.026097\n",
      "Train Epoch: 7 [40000/132000 (30%)]\tLoss: 0.011066\n",
      "Train Epoch: 7 [50000/132000 (38%)]\tLoss: 0.008237\n",
      "Train Epoch: 7 [60000/132000 (45%)]\tLoss: 0.023436\n",
      "Train Epoch: 7 [70000/132000 (53%)]\tLoss: 0.002534\n",
      "Train Epoch: 7 [80000/132000 (61%)]\tLoss: 0.058872\n",
      "Train Epoch: 7 [90000/132000 (68%)]\tLoss: 0.031566\n",
      "Train Epoch: 7 [100000/132000 (76%)]\tLoss: 0.007191\n",
      "Train Epoch: 7 [110000/132000 (83%)]\tLoss: 0.004965\n",
      "Train Epoch: 7 [120000/132000 (91%)]\tLoss: 0.005767\n",
      "Train Epoch: 7 [130000/132000 (98%)]\tLoss: 0.020468\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17924/18000 (100%)\n",
      "\n",
      "Train Epoch: 8 [0/132000 (0%)]\tLoss: 0.054684\n",
      "Train Epoch: 8 [10000/132000 (8%)]\tLoss: 0.013233\n",
      "Train Epoch: 8 [20000/132000 (15%)]\tLoss: 0.000939\n",
      "Train Epoch: 8 [30000/132000 (23%)]\tLoss: 0.005746\n",
      "Train Epoch: 8 [40000/132000 (30%)]\tLoss: 0.002783\n",
      "Train Epoch: 8 [50000/132000 (38%)]\tLoss: 0.002877\n",
      "Train Epoch: 8 [60000/132000 (45%)]\tLoss: 0.003147\n",
      "Train Epoch: 8 [70000/132000 (53%)]\tLoss: 0.006728\n",
      "Train Epoch: 8 [80000/132000 (61%)]\tLoss: 0.009392\n",
      "Train Epoch: 8 [90000/132000 (68%)]\tLoss: 0.014070\n",
      "Train Epoch: 8 [100000/132000 (76%)]\tLoss: 0.004408\n",
      "Train Epoch: 8 [110000/132000 (83%)]\tLoss: 0.005400\n",
      "Train Epoch: 8 [120000/132000 (91%)]\tLoss: 0.056707\n",
      "Train Epoch: 8 [130000/132000 (98%)]\tLoss: 0.003165\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 17927/18000 (100%)\n",
      "\n",
      "Train Epoch: 9 [0/132000 (0%)]\tLoss: 0.004999\n",
      "Train Epoch: 9 [10000/132000 (8%)]\tLoss: 0.029713\n",
      "Train Epoch: 9 [20000/132000 (15%)]\tLoss: 0.060112\n",
      "Train Epoch: 9 [30000/132000 (23%)]\tLoss: 0.008554\n",
      "Train Epoch: 9 [40000/132000 (30%)]\tLoss: 0.001510\n",
      "Train Epoch: 9 [50000/132000 (38%)]\tLoss: 0.027349\n",
      "Train Epoch: 9 [60000/132000 (45%)]\tLoss: 0.013105\n",
      "Train Epoch: 9 [70000/132000 (53%)]\tLoss: 0.000569\n",
      "Train Epoch: 9 [80000/132000 (61%)]\tLoss: 0.006119\n",
      "Train Epoch: 9 [90000/132000 (68%)]\tLoss: 0.005253\n",
      "Train Epoch: 9 [100000/132000 (76%)]\tLoss: 0.072459\n",
      "Train Epoch: 9 [110000/132000 (83%)]\tLoss: 0.019248\n",
      "Train Epoch: 9 [120000/132000 (91%)]\tLoss: 0.005139\n",
      "Train Epoch: 9 [130000/132000 (98%)]\tLoss: 0.022783\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 17925/18000 (100%)\n",
      "\n",
      "Train Epoch: 10 [0/132000 (0%)]\tLoss: 0.077868\n",
      "Train Epoch: 10 [10000/132000 (8%)]\tLoss: 0.006768\n",
      "Train Epoch: 10 [20000/132000 (15%)]\tLoss: 0.015710\n",
      "Train Epoch: 10 [30000/132000 (23%)]\tLoss: 0.002184\n",
      "Train Epoch: 10 [40000/132000 (30%)]\tLoss: 0.066835\n",
      "Train Epoch: 10 [50000/132000 (38%)]\tLoss: 0.001488\n",
      "Train Epoch: 10 [60000/132000 (45%)]\tLoss: 0.002551\n",
      "Train Epoch: 10 [70000/132000 (53%)]\tLoss: 0.046772\n",
      "Train Epoch: 10 [80000/132000 (61%)]\tLoss: 0.093479\n",
      "Train Epoch: 10 [90000/132000 (68%)]\tLoss: 0.006340\n",
      "Train Epoch: 10 [100000/132000 (76%)]\tLoss: 0.005343\n",
      "Train Epoch: 10 [110000/132000 (83%)]\tLoss: 0.002578\n",
      "Train Epoch: 10 [120000/132000 (91%)]\tLoss: 0.003462\n",
      "Train Epoch: 10 [130000/132000 (98%)]\tLoss: 0.026084\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17920/18000 (100%)\n",
      "\n",
      "Train Epoch: 11 [0/132000 (0%)]\tLoss: 0.000913\n",
      "Train Epoch: 11 [10000/132000 (8%)]\tLoss: 0.007779\n",
      "Train Epoch: 11 [20000/132000 (15%)]\tLoss: 0.022400\n",
      "Train Epoch: 11 [30000/132000 (23%)]\tLoss: 0.000856\n",
      "Train Epoch: 11 [40000/132000 (30%)]\tLoss: 0.004538\n",
      "Train Epoch: 11 [50000/132000 (38%)]\tLoss: 0.027323\n",
      "Train Epoch: 11 [60000/132000 (45%)]\tLoss: 0.003919\n",
      "Train Epoch: 11 [70000/132000 (53%)]\tLoss: 0.003977\n",
      "Train Epoch: 11 [80000/132000 (61%)]\tLoss: 0.029559\n",
      "Train Epoch: 11 [90000/132000 (68%)]\tLoss: 0.019619\n",
      "Train Epoch: 11 [100000/132000 (76%)]\tLoss: 0.003245\n",
      "Train Epoch: 11 [110000/132000 (83%)]\tLoss: 0.000628\n",
      "Train Epoch: 11 [120000/132000 (91%)]\tLoss: 0.025472\n",
      "Train Epoch: 11 [130000/132000 (98%)]\tLoss: 0.004872\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 17925/18000 (100%)\n",
      "\n",
      "Train Epoch: 12 [0/132000 (0%)]\tLoss: 0.001603\n",
      "Train Epoch: 12 [10000/132000 (8%)]\tLoss: 0.024127\n",
      "Train Epoch: 12 [20000/132000 (15%)]\tLoss: 0.014993\n",
      "Train Epoch: 12 [30000/132000 (23%)]\tLoss: 0.001290\n",
      "Train Epoch: 12 [40000/132000 (30%)]\tLoss: 0.040469\n",
      "Train Epoch: 12 [50000/132000 (38%)]\tLoss: 0.017280\n",
      "Train Epoch: 12 [60000/132000 (45%)]\tLoss: 0.009689\n",
      "Train Epoch: 12 [70000/132000 (53%)]\tLoss: 0.057959\n",
      "Train Epoch: 12 [80000/132000 (61%)]\tLoss: 0.002628\n",
      "Train Epoch: 12 [90000/132000 (68%)]\tLoss: 0.083276\n",
      "Train Epoch: 12 [100000/132000 (76%)]\tLoss: 0.000485\n",
      "Train Epoch: 12 [110000/132000 (83%)]\tLoss: 0.011314\n",
      "Train Epoch: 12 [120000/132000 (91%)]\tLoss: 0.011246\n",
      "Train Epoch: 12 [130000/132000 (98%)]\tLoss: 0.003928\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 17928/18000 (100%)\n",
      "\n",
      "Train Epoch: 13 [0/132000 (0%)]\tLoss: 0.001199\n",
      "Train Epoch: 13 [10000/132000 (8%)]\tLoss: 0.002613\n",
      "Train Epoch: 13 [20000/132000 (15%)]\tLoss: 0.015141\n",
      "Train Epoch: 13 [30000/132000 (23%)]\tLoss: 0.043915\n",
      "Train Epoch: 13 [40000/132000 (30%)]\tLoss: 0.047784\n",
      "Train Epoch: 13 [50000/132000 (38%)]\tLoss: 0.006045\n",
      "Train Epoch: 13 [60000/132000 (45%)]\tLoss: 0.006477\n",
      "Train Epoch: 13 [70000/132000 (53%)]\tLoss: 0.016231\n",
      "Train Epoch: 13 [80000/132000 (61%)]\tLoss: 0.003536\n",
      "Train Epoch: 13 [90000/132000 (68%)]\tLoss: 0.018895\n",
      "Train Epoch: 13 [100000/132000 (76%)]\tLoss: 0.001639\n",
      "Train Epoch: 13 [110000/132000 (83%)]\tLoss: 0.011762\n",
      "Train Epoch: 13 [120000/132000 (91%)]\tLoss: 0.019772\n",
      "Train Epoch: 13 [130000/132000 (98%)]\tLoss: 0.003280\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 17913/18000 (100%)\n",
      "\n",
      "Best model saved!\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T16:33:40.769091Z",
     "start_time": "2026-02-03T16:33:40.767196Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1254f4cb237ccc4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
